{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucaNavarra/MC3/blob/main/MC3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importo le librerie e monto google drive"
      ],
      "metadata": {
        "id": "wb_KtCxXfOr4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QluujjJCcTC1"
      },
      "outputs": [],
      "source": [
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "import random\n",
        "from random import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6O9_UygQAURr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Check device"
      ],
      "metadata": {
        "id": "BKUFMSrkfGSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "h_mum9GrfC61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rendere l'esecuzione deterministica\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "GWlt4Qb5fd39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Esempio visualizzazione immagine e divisione train/val\n",
        "\n"
      ],
      "metadata": {
        "id": "zkeKK-q9fixV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#settare path delle immagini\n",
        "imgs_path = '/content/drive/MyDrive/uni-na-machine-learning-23-24-ii-sem-contest-3/'\n",
        "\n",
        "\n",
        "#Test visualizzazione immagine dal train set\n",
        "img1 = np.load(imgs_path+'train/train/benign/mcf10aCdExposed-01/mcf10aCdExposed-01_croppedCell_21.npy')\n",
        "img2 = np.load(imgs_path + 'train/train/malignant/mcf7CdExposed-04/mcf7CdExposed-04_croppedCell_12.npy')\n",
        "\n",
        "print(img1.shape)\n",
        "plt.figure()\n",
        "plt.imshow(img1)\n",
        "\n",
        "print(img2.shape)\n",
        "plt.figure()\n",
        "plt.imshow(img2)\n",
        "\n",
        "#Dalle shape vedo che le foto sono tutte quadrate ma la dimensione Ã¨ variabile\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#def split_train_val(root, classes):\n",
        "#  if \"val\" not in os.listdir(root):\n",
        "#    os.mkdir(root + '/val')\n",
        "#    for c in classes:\n",
        "#      os.mkdir(root + '/val/' + c)\n",
        "#\n",
        "#  for c in classes:\n",
        "#    list_folder = os.listdir(root + '/train' + '/' + c)\n",
        "#    for folder in list_folder:\n",
        "#        listofFiles = os.listdir(root + '/train' + '/' + c + '/' + folder)\n",
        "#        for file in listofFiles:\n",
        "#          if random.random() > 0.7:\n",
        "#            if folder not in os.listdir(root + '/val/' + c):\n",
        "#              os.mkdir(root + '/val/' + c + '/' + folder)\n",
        "#             shutil.move(root + 'train' + '/' + c + '/' + folder + '/' + file, root + 'val' + '/' + c + '/' + folder + '/' + file)\n",
        "\n",
        "#classes = ['benign', 'malignant']\n",
        "#split_train_val(imgs_path + 'train', classes)\n"
      ],
      "metadata": {
        "id": "OJfcB3WdfrIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class My_DatasetFolder(Dataset):\n",
        "    def __init__(self, root, transform, is_valid_file, list_classes):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.is_valid_file = is_valid_file\n",
        "        self.list_classes = list_classes\n",
        "        self.samples = self.__get_samples()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __get_samples(self):\n",
        "        ListFiles = []\n",
        "        for c in self.list_classes:\n",
        "            list_folder = os.listdir(self.root + '/' + c)\n",
        "            for folder in list_folder:\n",
        "                listofFiles = os.listdir(self.root + '/' + c + '/' + folder)\n",
        "                for file in listofFiles:\n",
        "                    if self.is_valid_file(self.root + '/' + c + '/' + folder + '/' + file):\n",
        "                        ListFiles.append((self.root + '/' + c + '/' + folder + '/' + file, self.list_classes.index(c)))\n",
        "        return ListFiles\n",
        "\n",
        "    def loader_fc(self, path):\n",
        "        img = np.load(path)\n",
        "        return img\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        path, target = self.samples[index]\n",
        "        sample = self.loader_fc(path)\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "        return sample, target\n",
        "\n",
        "# Definizione della trasformazione dei dati\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        #transforms.Resize((224,224)),\n",
        "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    'validation': transforms.Compose([\n",
        "        #transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Definizione dei set di dati utilizzando la tua classe My_DatasetFolder\n",
        "train_dataset = My_DatasetFolder(root=imgs_path + 'train/train',\n",
        "                                 transform=data_transforms['train'],\n",
        "                                 is_valid_file=lambda path: path.endswith('.npy'),\n",
        "                                 list_classes=['benign', 'malignant'])\n",
        "\n",
        "val_dataset = My_DatasetFolder(root=imgs_path + 'train/val',\n",
        "                               transform=data_transforms['validation'],\n",
        "                               is_valid_file=lambda path: path.endswith('.npy'),\n",
        "                               list_classes=['benign', 'malignant'])\n",
        "\n",
        "# Definizione dei DataLoader\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=32,\n",
        "                                               shuffle=True,\n",
        "                                               num_workers=2)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                             batch_size=32,\n",
        "                                             shuffle=False,\n",
        "                                             num_workers=2)\n",
        "\n",
        "# Raggruppo dei DataLoader in un dizionario\n",
        "dataloaders = {'train': train_dataloader, 'validation': val_dataloader}\n",
        "\n",
        "\n",
        "'''\n",
        "un esempio di utilizzo\n",
        "is_valid_file = lambda path: path.endswith('.npy')\n",
        "\n",
        "My_DatasetFolder(root = MyPath,  transform = data_transforms, is_valid_file = is_valid_file, list_classes = ['benign', 'malignant'])\n",
        "'''"
      ],
      "metadata": {
        "id": "DiJI4DMkAkA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outfeatures_train =[]\n",
        "'''\n",
        "data_transforms = transforms.Compose([\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Resize(224),   #questo Ã¨ solo un esempio!\n",
        "                                      ])\n",
        "'''\n",
        "'''\n",
        "Inserire il modello che si vuole considerare\n",
        "'''\n",
        "\n",
        "model = models.resnet50(pretrained=True).to(device)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "               nn.Linear(2048, 128),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Linear(128, 2)).to(device)\n",
        "'''\n",
        "class_list_train = []\n",
        "class_list_test = []\n",
        "classes = ['benign', 'malignant']\n",
        "data_dir = 'data'   #path dei dati\n",
        "\n",
        "for c in classes:\n",
        "  folder = os.listdir(data_dir + '/train/' + c)\n",
        "  for f in folder:\n",
        "    listImage = os.listdir(data_dir + '/train/' + c + '/' + f)\n",
        "    for input in listImage:\n",
        "      img = np.load(data_dir + '/train/' + c + '/' + f + '/' + input)\n",
        "      img = data_transforms(img).type(torch.FloatTensor).to(device)\n",
        "      img = img.unsqueeze_(0)\n",
        "      outputs = model(img)\n",
        "      outfeatures_train.append((np.squeeze(outputs.cpu().detach()).numpy()))\n",
        "      class_list_train.append(classes.index(c))\n",
        "'''"
      ],
      "metadata": {
        "id": "KgvjvuB5ApvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Estrazione di features sul train"
      ],
      "metadata": {
        "id": "ej8HSn1Mfx87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outfeatures_train =[]\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Resize(224),   #questo Ã¨ solo un esempio!\n",
        "                                      ])\n",
        "\n",
        "'''\n",
        "Inserire il modello che si vuole considerare\n",
        "'''\n",
        "\n",
        "model = ....\n",
        "model.eval()\n",
        "\n",
        "class_list_train = []\n",
        "class_list_test = []\n",
        "classes = ['benign', 'malignant']\n",
        "data_dir = 'data'   #path dei dati\n",
        "\n",
        "for c in classes:\n",
        "  folder = os.listdir(data_dir + '/train/' + c)\n",
        "  for f in folder:\n",
        "    listImage = os.listdir(data_dir + '/train/' + c + '/' + f)\n",
        "    for input in listImage:\n",
        "      img = np.load(data_dir + '/train/' + c + '/' + f + '/' + input)\n",
        "      img = data_transforms(img).type(torch.FloatTensor).to(device)\n",
        "      img = img.unsqueeze_(0)\n",
        "      outputs = model(img)\n",
        "      outfeatures_train.append((np.squeeze(outputs.cpu().detach()).numpy()))\n",
        "      class_list_train.append(classes.index(c))"
      ],
      "metadata": {
        "id": "sP1ipdYTf0sK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}