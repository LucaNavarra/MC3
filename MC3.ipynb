{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucaNavarra/MC3/blob/main/MC3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importo le librerie e monto google drive"
      ],
      "metadata": {
        "id": "wb_KtCxXfOr4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QluujjJCcTC1"
      },
      "outputs": [],
      "source": [
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "import random\n",
        "from random import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6O9_UygQAURr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Check device"
      ],
      "metadata": {
        "id": "BKUFMSrkfGSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "h_mum9GrfC61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rendere l'esecuzione deterministica\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "GWlt4Qb5fd39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Esempio visualizzazione immagine e divisione train/val\n",
        "\n"
      ],
      "metadata": {
        "id": "zkeKK-q9fixV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#settare path delle immagini\n",
        "imgs_path = '/content/drive/MyDrive/uni-na-machine-learning-23-24-ii-sem-contest-3/'\n",
        "\n",
        "\n",
        "#Test visualizzazione immagine dal train set\n",
        "img1 = np.load(imgs_path+'train/train/benign/mcf10aCdExposed-01/mcf10aCdExposed-01_croppedCell_21.npy')\n",
        "img2 = np.load(imgs_path + 'train/train/malignant/mcf7CdExposed-04/mcf7CdExposed-04_croppedCell_12.npy')\n",
        "\n",
        "print(img1.shape)\n",
        "plt.figure()\n",
        "plt.imshow(img1)\n",
        "\n",
        "print(img2.shape)\n",
        "plt.figure()\n",
        "plt.imshow(img2)\n",
        "\n",
        "#Dalle shape vedo che le foto sono tutte quadrate ma la dimensione Ã¨ variabile\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#def split_train_val(root, classes):\n",
        "#  if \"val\" not in os.listdir(root):\n",
        "#    os.mkdir(root + '/val')\n",
        "#    for c in classes:\n",
        "#      os.mkdir(root + '/val/' + c)\n",
        "#\n",
        "#  for c in classes:\n",
        "#    list_folder = os.listdir(root + '/train' + '/' + c)\n",
        "#    for folder in list_folder:\n",
        "#        listofFiles = os.listdir(root + '/train' + '/' + c + '/' + folder)\n",
        "#        for file in listofFiles:\n",
        "#          if random.random() > 0.7:\n",
        "#            if folder not in os.listdir(root + '/val/' + c):\n",
        "#              os.mkdir(root + '/val/' + c + '/' + folder)\n",
        "#             shutil.move(root + 'train' + '/' + c + '/' + folder + '/' + file, root + 'val' + '/' + c + '/' + folder + '/' + file)\n",
        "\n",
        "#classes = ['benign', 'malignant']\n",
        "#split_train_val(imgs_path + 'train', classes)\n"
      ],
      "metadata": {
        "id": "OJfcB3WdfrIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class My_DatasetFolder(Dataset):\n",
        "    def __init__(self, root, transform, is_valid_file, list_classes):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.is_valid_file = is_valid_file\n",
        "        self.list_classes = list_classes\n",
        "        self.samples = self.__get_samples()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __get_samples(self):\n",
        "        ListFiles = []\n",
        "        for c in self.list_classes:\n",
        "            list_folder = os.listdir(self.root + '/' + c)\n",
        "            for folder in list_folder:\n",
        "                listofFiles = os.listdir(self.root + '/' + c + '/' + folder)\n",
        "                for file in listofFiles:\n",
        "                    if self.is_valid_file(self.root + '/' + c + '/' + folder + '/' + file):\n",
        "                        ListFiles.append((self.root + '/' + c + '/' + folder + '/' + file, self.list_classes.index(c)))\n",
        "        return ListFiles\n",
        "\n",
        "    def loader_fc(self, path):\n",
        "        img = np.load(path)\n",
        "        return img\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        path, target = self.samples[index]\n",
        "        sample = self.loader_fc(path)\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "        return sample, target\n",
        "\n",
        "# Definizione della trasformazione dei dati\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    'validation': transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Definizione dei set di dati utilizzando la tua classe My_DatasetFolder\n",
        "train_dataset = My_DatasetFolder(root=imgs_path + 'train/train',\n",
        "                                 transform=data_transforms['train'],\n",
        "                                 is_valid_file=lambda path: path.endswith('.npy'),\n",
        "                                 list_classes=['benign', 'malignant'])\n",
        "\n",
        "val_dataset = My_DatasetFolder(root=imgs_path + 'train/val',\n",
        "                               transform=data_transforms['validation'],\n",
        "                               is_valid_file=lambda path: path.endswith('.npy'),\n",
        "                               list_classes=['benign', 'malignant'])\n",
        "\n",
        "# Definizione dei DataLoader\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=32,\n",
        "                                               shuffle=True,\n",
        "                                               num_workers=2)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                             batch_size=32,\n",
        "                                             shuffle=False,\n",
        "                                             num_workers=2)\n",
        "\n",
        "# Raggruppo dei DataLoader in un dizionario\n",
        "dataloaders = {'train': train_dataloader, 'validation': val_dataloader}\n",
        "\n",
        "# Raggruppo image datasets in un dizionario\n",
        "image_datasets = {'train': train_dataset, 'validation': val_dataset}\n",
        "\n",
        "'''\n",
        "un esempio di utilizzo\n",
        "is_valid_file = lambda path: path.endswith('.npy')\n",
        "\n",
        "My_DatasetFolder(root = MyPath,  transform = data_transforms, is_valid_file = is_valid_file, list_classes = ['benign', 'malignant'])\n",
        "'''"
      ],
      "metadata": {
        "id": "DiJI4DMkAkA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#outfeatures_train =[]\n",
        "\n",
        "model = models.resnet50(pretrained=True).to(device)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "               nn.Linear(2048, 128),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Linear(128, 2)).to(device)\n",
        "'''\n",
        "class_list_train = []\n",
        "class_list_test = []\n",
        "classes = ['benign', 'malignant']\n",
        "data_dir = 'data'   #path dei dati\n",
        "\n",
        "for c in classes:\n",
        "  folder = os.listdir(data_dir + '/train/' + c)\n",
        "  for f in folder:\n",
        "    listImage = os.listdir(data_dir + '/train/' + c + '/' + f)\n",
        "    for input in listImage:\n",
        "      img = np.load(data_dir + '/train/' + c + '/' + f + '/' + input)\n",
        "      img = data_transforms(img).type(torch.FloatTensor).to(device)\n",
        "      img = img.unsqueeze_(0)\n",
        "      outputs = model(img)\n",
        "      outfeatures_train.append((np.squeeze(outputs.cpu().detach()).numpy()))\n",
        "      class_list_train.append(classes.index(c))\n",
        "'''"
      ],
      "metadata": {
        "id": "KgvjvuB5ApvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters())"
      ],
      "metadata": {
        "id": "sP1ipdYTf0sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_model(model, criterion, optimizer, num_epochs=3):\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'validation']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                inputs = inputs.to(torch.float32)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(image_datasets[phase] )\n",
        "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
        "\n",
        "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
        "                                                        epoch_loss,\n",
        "                                                        epoch_acc))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "izIxzCfHYbQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Addestramento"
      ],
      "metadata": {
        "id": "Q7jiff3yYnG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_trained = train_model(model, criterion, optimizer, num_epochs=3)\n"
      ],
      "metadata": {
        "id": "VVpng1hvYdni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvo i pesi"
      ],
      "metadata": {
        "id": "QywdWEHLYqci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models\n",
        "!mkdir models/pytorch"
      ],
      "metadata": {
        "id": "fHmf4bRrYgmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_trained.state_dict(), 'models/pytorch/weights.h5')"
      ],
      "metadata": {
        "id": "swy7nAc7YiU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(pretrained=False).to(device)\n",
        "model.fc = nn.Sequential(\n",
        "               nn.Linear(2048, 128),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Linear(128, 2)).to(device)\n",
        "model.load_state_dict(torch.load('models/pytorch/weights.h5'))"
      ],
      "metadata": {
        "id": "K6kKVaD5YkAV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}